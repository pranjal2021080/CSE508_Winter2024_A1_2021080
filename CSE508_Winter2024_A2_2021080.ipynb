{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pEyZkIw2DTzn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import cv2\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/A2_Data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "product_data = {}\n",
        "rows_to_drop = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    product_id = row['Unnamed: 0']\n",
        "    image_urls = eval(row['Image'])\n",
        "    review_text = row['Review Text']\n",
        "\n",
        "    # Initialize an empty list to store image data\n",
        "    image_data = []\n",
        "\n",
        "    for url in image_urls:\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            if response.status_code == 200:\n",
        "                # Convert image data into PIL Image object\n",
        "                img = Image.open(BytesIO(response.content))\n",
        "                image_data.append(img)\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading image from {url}: {e}\")\n",
        "\n",
        "    # Check if any image data is available\n",
        "    if image_data:\n",
        "        product_data[product_id] = (image_data, review_text)\n",
        "    else:\n",
        "        rows_to_drop.append(index)\n",
        "\n",
        "# Drop rows with no image data\n",
        "df.drop(rows_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "4IAoGCA4DkyC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import ImageEnhance, ImageOps\n",
        "\n",
        "# Define a function to apply image pre-processing\n",
        "def preprocess_image(img):\n",
        "    # Convert PIL Image to numpy array\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    # Resize image\n",
        "    resized_img = cv2.resize(img_array, (new_width, new_height))  # Define new_width and new_height\n",
        "\n",
        "    # Apply contrast enhancement\n",
        "    contrast_enhancer = ImageEnhance.Contrast(Image.fromarray(resized_img))\n",
        "    contrast_factor = 1.5  # Adjust contrast factor as needed\n",
        "    contrast_enhanced_img = contrast_enhancer.enhance(contrast_factor)\n",
        "\n",
        "    # Apply geometric orientation (e.g., rotation)\n",
        "    rotation_angle = 30  # Rotate image by 30 degrees\n",
        "    rotated_img = np.array(contrast_enhanced_img.rotate(rotation_angle))\n",
        "\n",
        "    # Apply random flips (horizontal and vertical)\n",
        "    if np.random.rand() > 0.5:\n",
        "        flipped_img = cv2.flip(rotated_img, 0)  # Horizontal flip\n",
        "    else:\n",
        "        flipped_img = cv2.flip(rotated_img, 1)  # Vertical flip\n",
        "\n",
        "    # Apply brightness adjustment\n",
        "    brightness_enhancer = ImageEnhance.Brightness(Image.fromarray(flipped_img))\n",
        "    brightness_factor = 1.2  # Adjust brightness factor as needed\n",
        "    brightness_adjusted_img = brightness_enhancer.enhance(brightness_factor)\n",
        "\n",
        "    # Apply exposure adjustment\n",
        "    exposure_enhancer = ImageEnhance.Exposure(brightness_adjusted_img)\n",
        "    exposure_factor = 1.2  # Adjust exposure factor as needed\n",
        "    preprocessed_img = exposure_enhancer.enhance(exposure_factor)\n",
        "\n",
        "    return preprocessed_img\n",
        "\n",
        "# Iterate through product_data dictionary and apply pre-processing to each image\n",
        "for product_id, (image_data, review_text) in product_data.items():\n",
        "    preprocessed_images = []\n",
        "    for img in image_data:\n",
        "        preprocessed_img = preprocess_image(img)\n",
        "        preprocessed_images.append(preprocessed_img)\n",
        "\n",
        "    # Update product_data dictionary with preprocessed images\n",
        "    product_data[product_id] = (preprocessed_images, review_text)\n"
      ],
      "metadata": {
        "id": "mYSjrDDDEFb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "+import numpy as np\n",
        "from keras.applications import MobileNet\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# Load MobileNet model pre-trained on ImageNet dataset\n",
        "mobilenet_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Function to extract features from images using MobileNet\n",
        "def extract_mobilenet_features(image_paths):\n",
        "    features = []\n",
        "    for img_path in image_paths:\n",
        "        # Load and preprocess the image\n",
        "        img = image.load_img(img_path, target_size=(224, 224))\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = preprocess_input(img_array)\n",
        "\n",
        "        # Extract features using MobileNet model\n",
        "        features.append(mobilenet_model.predict(img_array))\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "# Example usage:\n",
        "# Assuming image_paths is a list containing paths to the images in the training set\n",
        "image_paths = ['image1.jpg', 'image2.jpg', ...]  # Replace with actual image paths\n",
        "features = extract_mobilenet_features(image_paths)\n",
        "\n",
        "# Now 'features' contains the extracted features for each image in the training set\n",
        "# You can use these features for training your classifier or any downstream task\n"
      ],
      "metadata": {
        "id": "tQAVqUyDFcv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize stemmer and lemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to perform text pre-processing\n",
        "def preprocess_text(text):\n",
        "    # Lower-casing\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Removing punctuations and stopwords\n",
        "    tokens = [token for token in tokens if token not in string.punctuation]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    return stemmed_tokens, lemmatized_tokens\n",
        "\n",
        "# Example usage:\n",
        "text = \"This is an example sentence for text preprocessing.\"\n",
        "stemmed_tokens, lemmatized_tokens = preprocess_text(text)\n",
        "print(\"Stemmed Tokens:\", stemmed_tokens)\n",
        "print(\"Lemmatized Tokens:\", lemmatized_tokens)\n"
      ],
      "metadata": {
        "id": "Y3_kC4c5HC3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sample textual reviews\n",
        "reviews = [\n",
        "    \"The movie was great and I loved it.\",\n",
        "    \"I didn't like the acting in the movie.\",\n",
        "    \"The plot of the movie was too predictable.\"\n",
        "]\n",
        "\n",
        "# Step 1: Tokenization and Step 2: Calculate TF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(reviews)\n",
        "\n",
        "# Step 3: Document Frequency (DF) is already calculated by TfidfVectorizer\n",
        "\n",
        "# Step 4: Inverse Document Frequency (IDF)\n",
        "idf_scores = tfidf_vectorizer.idf_\n",
        "\n",
        "# Step 5: Calculate TF-IDF Score\n",
        "tfidf_scores = tfidf_matrix.toarray()\n",
        "\n",
        "# Print TF-IDF scores\n",
        "print(\"TF-IDF Scores:\")\n",
        "for i, review in enumerate(reviews):\n",
        "    print(f\"Review {i+1}:\")\n",
        "    for j, word in enumerate(tfidf_vectorizer.get_feature_names_out()):\n",
        "        print(f\"{word}: {tfidf_scores[i][j]\n"
      ],
      "metadata": {
        "id": "3MlqucymHQ-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load extracted image features\n",
        "with open('image_features.pkl', 'rb') as f:\n",
        "    image_features = pickle.load(f)\n",
        "\n",
        "# Load TF-IDF scores for textual reviews\n",
        "with open('tfidf_scores.pkl', 'rb') as f:\n",
        "    tfidf_scores = pickle.load(f)\n",
        "\n",
        "def find_similar_images(input_image_features, image_features, top_k=3):\n",
        "    # Calculate cosine similarity between input image and all other images\n",
        "    similarities = cosine_similarity(input_image_features.reshape(1, -1), image_features)\n",
        "\n",
        "    # Get indices of top-k similar images\n",
        "    similar_indices = similarities.argsort()[0][-top_k:][::-1]\n",
        "\n",
        "    return similar_indices\n",
        "\n",
        "# Example input: Index of the input image and its associated review\n",
        "input_image_index = 0  # Assuming input_image_index is the index of the input image\n",
        "input_review_index = 0  # Assuming input_review_index is the index of the input review\n",
        "\n",
        "# Extract features of the input image\n",
        "input_image_features = image_features[input_image_index]\n",
        "\n",
        "# Find most similar images based on input image features\n",
        "similar_image_indices = find_similar_images(input_image_features, image_features)\n",
        "\n",
        "# Print the indices of the most similar images\n",
        "print(\"Indices of top similar images:\")\n",
        "for idx in similar_image_indices:\n",
        "    print(idx)\n"
      ],
      "metadata": {
        "id": "STXZw3tSHfJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load TF-IDF scores for textual reviews\n",
        "with open('tfidf_scores.pkl', 'rb') as f:\n",
        "    tfidf_scores = pickle.load(f)\n",
        "\n",
        "def find_similar_reviews(input_review_tfidf, all_reviews_tfidf, top_k=3):\n",
        "    # Calculate cosine similarity between input review and all other reviews\n",
        "    similarities = cosine_similarity(input_review_tfidf.reshape(1, -1), all_reviews_tfidf)\n",
        "\n",
        "    # Get indices of top-k similar reviews (excluding the input review itself)\n",
        "    similar_indices = similarities.argsort()[0][-top_k-1:-1][::-1]\n",
        "\n",
        "    return similar_indices\n",
        "\n",
        "# Example input: Index of the input review\n",
        "input_review_index = 0  # Assuming input_review_index is the index of the input review\n",
        "\n",
        "# Get TF-IDF scores for the input review\n",
        "input_review_tfidf = tfidf_scores[input_review_index]\n",
        "\n",
        "# Get TF-IDF scores for all reviews except the input review\n",
        "all_reviews_tfidf = np.delete(tfidf_scores, input_review_index, axis=0)\n",
        "\n",
        "# Find most similar reviews based on input review TF-IDF scores\n",
        "similar_review_indices = find_similar_reviews(input_review_tfidf, all_reviews_tfidf)\n",
        "\n",
        "# Print the indices of the most similar reviews\n",
        "print(\"Indices of top similar reviews (excluding input review itself):\")\n",
        "for idx in similar_review_indices:\n",
        "    print(idx)\n"
      ],
      "metadata": {
        "id": "ZEzhXxJnH_6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the indices of the most similar reviews\n",
        "with open('similar_review_indices.pkl', 'wb') as f:\n",
        "    pickle.dump(similar_review_indices, f)\n"
      ],
      "metadata": {
        "id": "hUIPGFG5Ico2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the indices of the most similar reviews\n",
        "with open('similar_review_indices.pkl', 'rb') as f:\n",
        "    similar_review_indices = pickle.load(f)\n",
        "\n",
        "# Print the loaded indices\n",
        "print(\"Loaded similar review indices:\")\n",
        "print(similar_review_indices)\n"
      ],
      "metadata": {
        "id": "8HOuAhHwImOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_composite_similarity(text_similarity_scores, image_similarity_scores):\n",
        "    \"\"\"\n",
        "    Computes the composite similarity score for pairs using text and image similarity scores.\n",
        "\n",
        "    Args:\n",
        "    - text_similarity_scores: Dictionary mapping text pairs to their similarity scores.\n",
        "    - image_similarity_scores: Dictionary mapping image pairs to their similarity scores.\n",
        "\n",
        "    Returns:\n",
        "    - Dictionary mapping pairs to their composite similarity scores.\n",
        "    \"\"\"\n",
        "    composite_scores = {}\n",
        "\n",
        "    # Check if the pairs in text_similarity_scores also exist in image_similarity_scores\n",
        "    for pair, text_score in text_similarity_scores.items():\n",
        "        if pair in image_similarity_scores:\n",
        "            # Calculate the composite similarity score\n",
        "            composite_score = (text_score + image_similarity_scores[pair]) / 2\n",
        "            composite_scores[pair] = composite_score\n",
        "\n",
        "    return composite_scores\n",
        "\n",
        "# Example similarity scores for text pairs (3a) and image pairs (3b)\n",
        "text_similarity_scores = {\n",
        "    ('pair1', 'text'): 0.75,\n",
        "    ('pair2', 'text'): 0.60,\n",
        "    ('pair3', 'text'): 0.85\n",
        "}\n",
        "\n",
        "image_similarity_scores = {\n",
        "    ('pair1', 'image'): 0.90,\n",
        "    ('pair2', 'image'): 0.70,\n",
        "    ('pair3', 'image'): 0.80\n",
        "}\n",
        "\n",
        "# Compute composite similarity scores\n",
        "composite_scores = compute_composite_similarity(text_similarity_scores, image_similarity_scores)\n",
        "\n",
        "# Output the composite similarity scores\n",
        "print(\"Composite Similarity Scores:\")\n",
        "for pair, score in composite_scores.items():\n",
        "    print(pair, \":\", score)\n"
      ],
      "metadata": {
        "id": "YXVkZ8dAJyik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the composite similarity scores in descending order\n",
        "sorted_scores = sorted(composite_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Output the ranked pairs based on composite similarity score\n",
        "print(\"Ranked Pairs based on Composite Similarity Score:\")\n",
        "for i, (pair, score) in enumerate(sorted_scores, start=1):\n",
        "    print(f\"{i}. {pair} : {score}\")\n"
      ],
      "metadata": {
        "id": "Cu2_uHYdKERt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_composite_similarity(text_similarity_scores, image_similarity_scores):\n",
        "    \"\"\"\n",
        "    Computes the composite similarity score for pairs using text and image similarity scores.\n",
        "\n",
        "    Args:\n",
        "    - text_similarity_scores: Dictionary mapping text pairs to their similarity scores.\n",
        "    - image_similarity_scores: Dictionary mapping image pairs to their similarity scores.\n",
        "\n",
        "    Returns:\n",
        "    - Dictionary mapping pairs to their composite similarity scores.\n",
        "    \"\"\"\n",
        "    composite_scores = {}\n",
        "\n",
        "    # Check if the pairs in text_similarity_scores also exist in image_similarity_scores\n",
        "    for pair, text_score in text_similarity_scores.items():\n",
        "        if pair in image_similarity_scores:\n",
        "            # Calculate the composite similarity score\n",
        "            composite_score = (text_score + image_similarity_scores[pair]) / 2\n",
        "            composite_scores[pair] = composite_score\n",
        "\n",
        "    return composite_scores\n",
        "\n",
        "# Example similarity scores for text pairs (3a) and image pairs (3b)\n",
        "text_similarity_scores = {\n",
        "    ('pair1', 'text'): 0.75,\n",
        "    ('pair2', 'text'): 0.60,\n",
        "    ('pair3', 'text'): 0.85\n",
        "}\n",
        "\n",
        "image_similarity_scores = {\n",
        "    ('pair1', 'image'): 0.90,\n",
        "    ('pair2', 'image'): 0.70,\n",
        "    ('pair3', 'image'): 0.80\n",
        "}\n",
        "\n",
        "# Compute composite similarity scores\n",
        "composite_scores = compute_composite_similarity(text_similarity_scores, image_similarity_scores)\n",
        "\n",
        "# Sort the composite similarity scores in descending order\n",
        "sorted_scores = sorted(composite_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Filter out pairs consisting of an image and a review\n",
        "top_ranked_pairs = [(pair, score) for pair, score in sorted_scores if pair[1] == 'text']\n",
        "\n",
        "# Output the top-ranked (image, review) pairs along with cosine similarity scores\n",
        "print(\"Top-ranked (image, review) pairs along with cosine similarity scores:\")\n",
        "for i, ((image, review), score) in enumerate(top_ranked_pairs[:10], start=1):  # Adjust the range as needed\n",
        "    print(f\"{i}. Image: {image}, Review: {review}, Cosine Similarity: {score}\")\n"
      ],
      "metadata": {
        "id": "5plB3k3EKdOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average composite similarity score for text-based retrieval\n",
        "text_composite_scores = [score for pair, score in sorted_scores if pair[1] == 'text']\n",
        "avg_text_score = sum(text_composite_scores) / len(text_composite_scores)\n",
        "\n",
        "# Calculate average composite similarity score for image-based retrieval\n",
        "image_composite_scores = [score for pair, score in sorted_scores if pair[1] == 'image']\n",
        "avg_image_score = sum(image_composite_scores) / len(image_composite_scores)\n",
        "\n",
        "# Output average composite similarity scores\n",
        "print(\"Average Composite Similarity Score for Text-based Retrieval:\", avg_text_score)\n",
        "print(\"Average Composite Similarity Score for Image-based Retrieval:\", avg_image_score)\n",
        "\n",
        "# Compare the average scores\n",
        "if avg_text_score > avg_image_score:\n",
        "    print(\"Text-based retrieval yields a better similarity score.\")\n",
        "elif avg_text_score < avg_image_score:\n",
        "    print(\"Image-based retrieval yields a better similarity score.\")\n",
        "else:\n",
        "    print(\"Both retrieval techniques yield the same average similarity score.\")\n"
      ],
      "metadata": {
        "id": "HZE0tHXJK5SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample code demonstrating challenges and potential improvements in retrieval process\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from PIL import Image\n",
        "\n",
        "# Sample data\n",
        "text_data = [\"This is a sample text about a dog.\", \"A cat is sleeping on the sofa.\"]\n",
        "image_paths = [\"dog.jpg\", \"cat.jpg\"]\n",
        "\n",
        "# 1. Semantic Gap Challenge: Improving feature representations\n",
        "# Text data processing\n",
        "vectorizer = TfidfVectorizer()\n",
        "text_features = vectorizer.fit_transform(text_data)\n",
        "\n",
        "# Image data processing\n",
        "def preprocess_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((224, 224))  # Resize image for ResNet50\n",
        "    img = np.array(img)\n",
        "    img = preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "# Load pre-trained ResNet50 model for feature extraction\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "# Extract image features\n",
        "image_features = []\n",
        "for path in image_paths:\n",
        "    img = preprocess_image(path)\n",
        "    img_feature = resnet_model.predict(np.expand_dims(img, axis=0))\n",
        "    image_features.append(img_feature)\n",
        "\n",
        "# 2. Data Heterogeneity Challenge: Integrating multiple modalities\n",
        "# Combine text and image features\n",
        "combined_features = np.concatenate((text_features.toarray(), np.array(image_features).squeeze()), axis=1)\n",
        "\n",
        "# 3. Scalability Challenge: Efficient indexing and retrieval\n",
        "# Perform similarity search using cosine similarity\n",
        "similarity_matrix = cosine_similarity(combined_features)\n",
        "\n",
        "# 4. Domain-Specific Challenges: Custom processing for specific domains\n",
        "# For example, in medical imaging, you might preprocess images differently or use domain-specific models\n",
        "\n",
        "# 5. Evaluation Metrics: Choose appropriate metrics for evaluation\n",
        "# Evaluate retrieval performance using precision, recall, etc.\n",
        "\n",
        "# 6. User Interaction and Feedback: Incorporate user feedback\n",
        "# Implement interactive retrieval system with feedback mechanism\n",
        "\n",
        "# 7. Ethical and Privacy Considerations: Address ethical concerns\n",
        "# Implement privacy-preserving techniques and fairness-aware algorithms\n",
        "\n",
        "# Example usage of similarity matrix\n",
        "print(\"Similarity Matrix:\")\n",
        "print(similarity_matrix)\n"
      ],
      "metadata": {
        "id": "r5hTE2V9L6Qe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}